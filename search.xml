<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>《机器学习》第四章-决策树</title>
    <url>/zhangjunlong.github.io/2022/05/27/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h1 id="第四章-决策树"><a href="#第四章-决策树" class="headerlink" title="第四章 决策树"></a>第四章 决策树</h1><h2 id="4-1-决策树算法流程"><a href="#4-1-决策树算法流程" class="headerlink" title="4.1 决策树算法流程"></a>4.1 决策树算法流程</h2><p><img src="/zhangjunlong.github.io/2022/05/27/%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/决策树算法.png" alt="决策树算法"></p>
<p>说明：</p>
<ul>
<li>第12行应该是continue？属性a*的每一个值都要生成子节点吧！</li>
<li>关键是第8行，从A中选择最优划分属性。</li>
</ul>
<h2 id="4-2-划分选择"><a href="#4-2-划分选择" class="headerlink" title="4.2 划分选择"></a>4.2 划分选择</h2><p>总目标：提高节点的纯度，本质上也反映了奥卡姆剃刀原则，即越简单的越好。</p>
<h3 id="4-2-1-方案一：基于信息增益"><a href="#4-2-1-方案一：基于信息增益" class="headerlink" title="4.2.1 方案一：基于信息增益"></a>4.2.1 方案一：基于信息增益</h3><h4 id="信息熵："><a href="#信息熵：" class="headerlink" title="信息熵："></a>信息熵：</h4><script type="math/tex; mode=display">
Ent(D)=-\sum_{k=1}^{|y|}p_klog_2p_k</script><p>其中，D代表当前样本，第k类样本所占的比例为$p_k$，若所有$p_k$都小于1，则$Ent(D)$取正数，假设只有一类样本，即至纯，那么信息熵为0，最小，因此也说明了信息熵越大则越杂乱越不纯。</p>
<h4 id="信息增益："><a href="#信息增益：" class="headerlink" title="信息增益："></a>信息增益：</h4><script type="math/tex; mode=display">
Gain(D,a) = Ent(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v)</script><p>其中，a表示用属性a对样本集D进行划分，假设属性a的取值为$a^1,a^2,…,a^V$，$D^v$表示样本D中属性a取$a^v$的样本。</p>
<p>说明：</p>
<ul>
<li>信息增益对可取值较多的属性有偏好，增益率可以将一定程度上消除这种偏好。</li>
</ul>
<h4 id="ID3决策树："><a href="#ID3决策树：" class="headerlink" title="ID3决策树："></a>ID3决策树：</h4><p>该决策树就是用最大化信息增益为准则选取最优划分属性，然后用<a href="#4-1">4.1</a>生成决策树。</p>
<p>ID3，Iterative Dichotomiser，迭代二分类器</p>
<h4 id="增益率："><a href="#增益率：" class="headerlink" title="增益率："></a>增益率：</h4><script type="math/tex; mode=display">
Gain\_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}\\
\\
IV(a)=-\sum^V_{v=1}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}</script><p>其中IV表示intrinsic value，固有值的意思，可取值较多时，IV值也较大，IV值直观上看是属性a划分的信息熵。</p>
<h4 id="C4-5决策树："><a href="#C4-5决策树：" class="headerlink" title="C4.5决策树："></a>C4.5决策树：</h4><p>该决策树利用了增益率来消除单纯信息增益带来的多取值属性的偏好，但也不是直接使用信息增益率，因为增益率毕竟只表示增益率，消除了增益本身的影响。</p>
<p>该决策树先从候选划分属性中找出信息增益高于平均的属性，再从总选择增益率最高的。</p>
<p>该决策树还进行了缺失值处理，<a href="#4-4-2">4.4.2</a></p>
<h4 id="基尼指数："><a href="#基尼指数：" class="headerlink" title="基尼指数："></a>基尼指数：</h4><script type="math/tex; mode=display">
\begin{align}
Gini(D)&=\sum_{k=1}^{|y|}\sum_{k'\neq k}p_kp_{k'}\\
&=1-\sum_{k=1}^{|y|}p_k^2
\end{align}</script><p>直观上看，Gini反映了从样本中随机抽取两个样本，其标签不一致的概率，因此Gini越小，样本集纯度越高。</p>
<p>类似信息增益，定义基尼指数：</p>
<script type="math/tex; mode=display">
Gini\_index(D,a)=\sum_{v=1}^V\frac{|D^v|}{|D|}Gini(D^v)</script><h4 id="CART决策树："><a href="#CART决策树：" class="headerlink" title="CART决策树："></a>CART决策树：</h4><p>该决策树就用了基尼指数作为选择最优划分属性的标注，然后用<a href="#4-1">4.1</a>的算法生成决策树。</p>
<h2 id="4-3-剪枝处理-pruning"><a href="#4-3-剪枝处理-pruning" class="headerlink" title="4.3 剪枝处理(pruning)"></a>4.3 剪枝处理(pruning)</h2><p>目的：划分过细导致过拟合，因此剪枝用来避免过拟合。</p>
<h3 id="4-3-1-预剪枝-prepruning"><a href="#4-3-1-预剪枝-prepruning" class="headerlink" title="4.3.1 预剪枝(prepruning):"></a>4.3.1 预剪枝(prepruning):</h3><p>一句话描述：正式生成分支之前，可以先使用测试集来测试一下生成分支之前和之后（将分支节点当作叶节点处理，标签用占比最大的标签）的性能，有提升则进行划分，否则不划分。</p>
<p>说明：</p>
<ul>
<li>优点：可以提高运算效率，节省计算资源，一定程度可以避免过拟合；</li>
<li>缺点：“试一下”的具体操作实际为贪心策略，无法保证继续划分下去之后性能一定下降。</li>
</ul>
<h3 id="4-3-2-后剪枝-postpruning"><a href="#4-3-2-后剪枝-postpruning" class="headerlink" title="4.3.2 后剪枝(postpruning)"></a>4.3.2 后剪枝(postpruning)</h3><p>一句话描述：在按照规则生成决策树后，按照节点生成的反向顺序，逐一判断节点取消分支是否能提高性能，直至根节点。</p>
<p>说明：</p>
<ul>
<li>优点：欠拟合风险小，泛化性能优于预剪枝（从过程上看似乎不那么贪心）。</li>
<li>缺点：慢。</li>
</ul>
<h2 id="4-4-连续值与缺失值"><a href="#4-4-连续值与缺失值" class="headerlink" title="4.4 连续值与缺失值"></a>4.4 连续值与缺失值</h2><h3 id="4-4-1-连续值"><a href="#4-4-1-连续值" class="headerlink" title="4.4.1 连续值"></a>4.4.1 连续值</h3><p>即连续属性而不是离散属性。</p>
<h4 id="基本策略——二分法"><a href="#基本策略——二分法" class="headerlink" title="基本策略——二分法:"></a>基本策略——二分法:</h4><p>将样本集中的连续属性按照从小到大的顺序排列，取一个截断点，将样本分为两类，这样就形成了分支节点。问题转化成了截断点如何选取，而这个问题同样可以用最大化信息增益来解决。</p>
<p>说明：</p>
<ul>
<li>与离散属性不同，连续属性可以重复使用。</li>
</ul>
<h3 id="4-4-2-缺失值"><a href="#4-4-2-缺失值" class="headerlink" title="4.4.2 缺失值"></a>4.4.2 缺失值</h3><p><span id="4-4-2"> </span>就是一些样本的属性数据不完整。面对这样样本集，有两个问题要解决：①如何选择最优属性；②如何对样本划分。</p>
<p>基本思路：赋予样本以权值。</p>
<p>给定训练集D和属性a，令$\widetilde{D}$表示D中在a上没有样本缺失的子集。</p>
<p>假定a有V个可取值，${a^1,a^2,…,a^V}$，令$\widetilde{D}^v$表$\widetilde{D}$中属性a取$a^v$的样本子集。</p>
<p>令$\widetilde{D}_k$表示$\widetilde{D}$中属于第k类的样本子集。</p>
<p>定义:</p>
<script type="math/tex; mode=display">
\begin{align}

\rho&=\frac{\sum_{\boldsymbol{x}\in\widetilde{D}}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in D}w_{\boldsymbol{x}}}\\
\widetilde{p}_k&=\frac{\sum_{\boldsymbol{x}\in\widetilde{D}_k}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in \widetilde{D}}w_{\boldsymbol{x}}},1\le k\le|y|\\
\widetilde{r}_v&=\frac{\sum_{\boldsymbol{x}\in\widetilde{D}^v}w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x}\in \widetilde{D}}w_{\boldsymbol{x}}},1\le v\le V

\end{align}</script><h4 id="4-4-2-1-最优属性的选择"><a href="#4-4-2-1-最优属性的选择" class="headerlink" title="4.4.2.1 最优属性的选择"></a>4.4.2.1 最优属性的选择</h4><p>同样基于信息增益:</p>
<script type="math/tex; mode=display">
\begin{align}

Gain(D,a)&=\rho\times Gain(\widetilde{D},a)\\
&=\rho\times (Ent(\widetilde{D})-\sum_{v=1}^{V}\widetilde{r}_vEnt(\widetilde{D}^v))
\end{align}</script><p>其中</p>
<script type="math/tex; mode=display">
Ent(\widetilde{D}) = -\sum_{k=1}^{|y|}\widetilde{p}_klog_2\widetilde{p}_k</script><h4 id="4-4-2-2-样本划分"><a href="#4-4-2-2-样本划分" class="headerlink" title="4.4.2.2 样本划分"></a>4.4.2.2 样本划分</h4><p>对有缺失值的样本，则将样本划入所有子节点，且样本权值在属性值$a^v$对应的子节点中调整为$\widetilde{r}_v$。就是相当于以不同的概率划分到对应的属性值节点中，后续选择最优属性时，$\rho$值会变大。</p>
<h2 id="4-5-多变量决策树"><a href="#4-5-多变量决策树" class="headerlink" title="4.5 多变量决策树"></a>4.5 多变量决策树</h2><p>对决策树的思想理解很重要，是从几何的观点出发。</p>
<p>即决策树的每一个非叶节点，都对应坐标空间的一个或多个（分支≥3时）超平面。</p>
<p>因此有了“斜决策树”（oblique decision tree），每个非叶节点是一个形如$\sum_{i=1}^dw_ia_t=t$的线性分类器，其中权重和常数可以通过学习而得。</p>
<h3 id="4-5-1-典型多变量决策树"><a href="#4-5-1-典型多变量决策树" class="headerlink" title="4.5.1 典型多变量决策树"></a>4.5.1 典型多变量决策树</h3><p>OC1、感知机树</p>
<h2 id="4-6-阅读材料"><a href="#4-6-阅读材料" class="headerlink" title="4.6 阅读材料"></a>4.6 阅读材料</h2><ul>
<li>可以拓展阅读C4.5Rule。</li>
<li>用信息增益、增益率和基尼指数就够了，其它改进的程度不大。</li>
<li>多变量决策树可以和神经网络、感知机结合。</li>
<li>决策树的增量学习算法：ID4、ID5R、ITI，增量学习可以有效地降低新样本加入后的训练时间开销，适合工业化，但是多步增量学习后的模型会与基于全部数据训练而得的模型有较大差别。</li>
</ul>
]]></content>
      <categories>
        <category>计算机技术</category>
        <category>机器学习</category>
        <category>读书笔记</category>
        <category>周志华：《机器学习》</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>计算机技术</tag>
      </tags>
  </entry>
  <entry>
    <title>《货币金融学》第二章</title>
    <url>/zhangjunlong.github.io/2023/04/01/%E3%80%8A%E8%B4%A7%E5%B8%81%E9%87%91%E8%9E%8D%E5%AD%A6%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0/</url>
    <content><![CDATA[<h1 id="《货币金融学》第二章——"><a href="#《货币金融学》第二章——" class="headerlink" title="《货币金融学》第二章——"></a>《货币金融学》第二章——</h1>]]></content>
      <categories>
        <category>经济金融</category>
        <category>货币金融</category>
        <category>读书笔记</category>
        <category>Frederic Stanley Mishkin 《货币金融学》</category>
      </categories>
      <tags>
        <tag>金融</tag>
      </tags>
  </entry>
  <entry>
    <title>《货币金融学》第一章</title>
    <url>/zhangjunlong.github.io/2023/03/29/%E3%80%8A%E8%B4%A7%E5%B8%81%E9%87%91%E8%9E%8D%E5%AD%A6%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
    <content><![CDATA[<h1 id="《货币金融学》第一章——为什么研究货币、银行与金融市场"><a href="#《货币金融学》第一章——为什么研究货币、银行与金融市场" class="headerlink" title="《货币金融学》第一章——为什么研究货币、银行与金融市场"></a>《货币金融学》第一章——为什么研究货币、银行与金融市场</h1><p>第一章主要从“为什么”的角度讲一些基本概念。</p>
<h2 id="1-为什么研究金融市场"><a href="#1-为什么研究金融市场" class="headerlink" title="1. 为什么研究金融市场"></a>1. 为什么研究金融市场</h2><h3 id="1-1-金融市场"><a href="#1-1-金融市场" class="headerlink" title="1.1. 金融市场"></a>1.1. 金融市场</h3><p><strong><u>金融市场</u></strong>(financial markets)，通俗地讲，在金融市场中，资金从有闲置货币的人手中转移到资金短缺的人手中；本质地讲，金融市场将资金从没有生产用途的人转移至有生产用途的人，<strong>从而提升了经济效率</strong>。</p>
<p><strong><u>债券市场</u></strong>与<strong><u>股票市场</u></strong>都属于金融市场，但金融市场不仅包含这俩。</p>
<h3 id="1-2-债券市场与利率"><a href="#1-2-债券市场与利率" class="headerlink" title="1.2. 债券市场与利率"></a>1.2. 债券市场与利率</h3><p><strong><u>证券</u></strong>(security，又称金融工具)是对发行人未来收入与<strong>资产</strong>(asset，金融索取权或隶属于所有权的财产权)。</p>
<ul>
<li><strong><u>债券</u></strong>是债务证券，它承诺在一个特定的时间段中进行定期支付，通俗地讲就是借钱。<ul>
<li>债券市场可以帮助政府和企业筹集到所需要的资金，并且是决定利率的场所。</li>
<li><strong><u>利率</u></strong>好懂，通常用年利率表示。<ul>
<li>对个人而言，①一方面提高融资成本，从而迟缓个人的购买决策；②另一方面鼓励个人增加储蓄，因为可以获得更多的利息收入。</li>
<li>从宏观角度，①利率影响消费者支出和储蓄的意愿，②也影响企业的投资决策。</li>
<li>比如企业在高利率的情况下可能会选择推迟建设新工厂，从而对就业产生影响。</li>
<li>书上希望<strong><em>解释过去35年间利率的重大变动，研究其趋势，可以作为一个小话题研究一下</em></strong>。</li>
<li>不同种类的债券利率不同，有很大差别。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="1-3-股票市场"><a href="#1-3-股票市场" class="headerlink" title="1.3. 股票市场"></a>1.3. 股票市场</h3><p><strong><u>普通股</u></strong>(common stock)，简称股票(stock)，代表持有者对公司的<strong>所有权</strong>，对公司收益和资产有索取权。</p>
<ul>
<li>企业通过发行股票来对其业务进行<strong>筹资</strong>。</li>
<li>股票价格很重要，它可以让人发财和破产，书中采用道琼斯工业平均指数衡量股票价格。</li>
</ul>
<p><img src="/zhangjunlong.github.io/2023/03/29/%E3%80%8A%E8%B4%A7%E5%B8%81%E9%87%91%E8%9E%8D%E5%AD%A6%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0/Dow_Jones_Industrial_Average.png" alt="DJIA"></p>
<ul>
<li><p><strong><u>道琼斯工业指数</u></strong>(Dow Jones Industrial Average, DJIA)是由华尔街日报和道琼斯公司创建者查尔斯·道创造的几种股票市场指数之一。这个指数作为测量美国股票市场上工业构成的发展，是最悠久的美国市场指数之一。 平均指数包括美国30家最大、最知名的上市公司，具体名单可参见<a href="https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average">wiki</a>。</p>
</li>
<li><p>股票价格所带来的影响：</p>
<ul>
<li><p><strong>对个人来说：</strong>股票价格的巨大波动通过影响投资者的财富规模而作用于他们的支出意愿，<em>这句话是说股票涨了人们消费意愿更高吗？</em></p>
</li>
<li><p><strong>对企业来说：</strong>股票价格能够影响企业通过发行股票<strong>筹集到的资金规模</strong>，<strong>决定了他们用于投资的支出</strong>。</p>
</li>
</ul>
</li>
</ul>
<h2 id="2-为什么研究金融机构和银行"><a href="#2-为什么研究金融机构和银行" class="headerlink" title="2. 为什么研究金融机构和银行"></a>2. 为什么研究金融机构和银行</h2><p>银行哈哈哈哈哈哈</p>
]]></content>
      <categories>
        <category>经济金融</category>
        <category>货币金融</category>
        <category>读书笔记</category>
        <category>Frederic Stanley Mishkin 《货币金融学》</category>
      </categories>
      <tags>
        <tag>金融</tag>
      </tags>
  </entry>
</search>
